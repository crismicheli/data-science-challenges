{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67648a52",
   "metadata": {},
   "source": [
    "# Reordered / Minimal Notebook: Predicting multiple binary targets\n",
    "**Purpose:** A compact notebook that keeps only the necessary steps:\n",
    "- Load data\n",
    "- Quick EDA (target identification, missingness, class balance)\n",
    "- Preprocessing\n",
    "- Train multi-output RandomForest (per-target class balance considered)\n",
    "- Evaluate using precision/recall/F1 for the 1-class and 0-class\n",
    "- Predict on unlabeled clients and discuss validation strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4926783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23248672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (adjust filename if needed)\n",
    "df = pd.read_csv(\"Technical_Interview_dataset2.csv\")\n",
    "print('Rows, cols:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be8b073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify target columns (ending with '_tgt') and features\n",
    "target_cols = [c for c in df.columns if c.endswith('_tgt')]\n",
    "print('Targets found:', target_cols)\n",
    "feature_cols = [c for c in df.columns if c not in target_cols + ['client_id']]\n",
    "print('Number of features:', len(feature_cols))\n",
    "# Quick check for duplicates\n",
    "print('Duplicate client_id count:', df['client_id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91736457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missingness and class balance per target\n",
    "missing = df[target_cols].isnull().mean().sort_values(ascending=False)\n",
    "counts = df[target_cols].apply(lambda s: s.value_counts(dropna=False))\n",
    "display(missing.to_frame('fraction_null').T)\n",
    "display(counts)\n",
    "# Show features missingness briefly\n",
    "feat_missing = df[feature_cols].isnull().mean().sort_values(ascending=False).head(10)\n",
    "display(feat_missing.to_frame('fraction_null'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a718dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For modeling we'll use rows that have at least one non-null target.\n",
    "# We'll train a multi-output model treating NaN as unlabeled (excluded from loss).\n",
    "df_model = df.copy()\n",
    "has_label = df_model[target_cols].notnull().any(axis=1)\n",
    "df_model = df_model[has_label].reset_index(drop=True)\n",
    "print('Rows with at least one label:', df_model.shape[0])\n",
    "\n",
    "# For rows where a particular target is null, we will mask those during evaluation.\n",
    "X = df_model[feature_cols].copy()\n",
    "Y = df_model[target_cols].copy()  # keep NaNs\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874cb6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: numeric imputation + scaling for numeric features; one-hot encode categoricals if needed.\n",
    "# We'll do a simple strategy: numeric columns -> imputer+scaler, object columns -> simple impute with 'missing' then get_dummies.\n",
    "num_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "print('Numeric cols:', len(num_cols), 'Categorical cols:', len(cat_cols))\n",
    "\n",
    "# Impute numeric\n",
    "num_pipe = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "X_num = pd.DataFrame(num_pipe.fit_transform(X[num_cols]), columns=num_cols, index=X.index)\n",
    "\n",
    "# Categorical handling (lightweight)\n",
    "if cat_cols:\n",
    "    X_cat = X[cat_cols].fillna('missing').astype(str)\n",
    "    X_cat = pd.get_dummies(X_cat, drop_first=True)\n",
    "    X_prepared = pd.concat([X_num, X_cat], axis=1)\n",
    "else:\n",
    "    X_prepared = X_num\n",
    "\n",
    "print('Prepared X shape:', X_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple train/test split. For stratification we'll use the first non-null target as a proxy.\n",
    "first_label = None\n",
    "for c in target_cols:\n",
    "    if df_model[c].notnull().any():\n",
    "        first_label = c\n",
    "        break\n",
    "print('Proxy stratify target:', first_label)\n",
    "\n",
    "y_strat = df_model[first_label].fillna(0)  # fillna with 0 for stratify proxy\n",
    "X_train, X_test, y_train_df, y_test_df = train_test_split(\n",
    "    X_prepared, Y, test_size=0.2, random_state=42, stratify=y_strat\n",
    ")\n",
    "print('Train/test shapes:', X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b5f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a MultiOutputClassifier using RandomForest per target.\n",
    "# We'll set each RandomForest to use class_weight='balanced' to penalize misclassifying minority (1) class.\n",
    "base_rf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42, class_weight='balanced')\n",
    "multi_clf = MultiOutputClassifier(base_rf, n_jobs=-1)\n",
    "multi_clf.fit(X_train, y_train_df.fillna(0))  # sklearn requires no NaNs at fit; for training we fill NaN with 0 but mask during eval\n",
    "\n",
    "# Save model\n",
    "joblib.dump(multi_clf, '/mnt/data/multi_clf_joblib.pkl')\n",
    "print('Model trained and saved to /mnt/data/multi_clf_joblib.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate per target, masking rows where that target was null in y_test_df\n",
    "results = {}\n",
    "for i, tgt in enumerate(target_cols):\n",
    "    mask = y_test_df[tgt].notnull()\n",
    "    if mask.sum() == 0:\n",
    "        print(f'No test labels for {tgt}, skipping')\n",
    "        continue\n",
    "    y_true = y_test_df.loc[mask, tgt].astype(int)\n",
    "    y_pred = multi_clf.predict(X_test.loc[mask])\n",
    "    # If predict returns array of shape (n_samples, n_targets)\n",
    "    if y_pred.ndim == 2:\n",
    "        y_pred_t = y_pred[:, i]\n",
    "    else:\n",
    "        y_pred_t = y_pred\n",
    "    p, r, f, sup = precision_recall_fscore_support(y_true, y_pred_t, labels=[1,0], zero_division=0)\n",
    "    results[tgt] = {'precision_1': p[0], 'recall_1': r[0], 'f1_1': f[0], 'support': int(sup.sum())}\n",
    "\n",
    "pd.DataFrame(results).T.sort_values('f1_1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1562117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on rows where a given target is null (population to score)\n",
    "df_unlabeled = df[df[target_cols].isnull().any(axis=1)].copy()\n",
    "print('Unlabeled rows count:', df_unlabeled.shape[0])\n",
    "\n",
    "if not df_unlabeled.empty:\n",
    "    X_unl = df_unlabeled[feature_cols]\n",
    "    # apply same preprocessing\n",
    "    X_unl_num = pd.DataFrame(num_pipe.transform(X_unl[num_cols]), columns=num_cols, index=X_unl.index)\n",
    "    if cat_cols:\n",
    "        X_unl_cat = X_unl[cat_cols].fillna('missing').astype(str)\n",
    "        X_unl_cat = pd.get_dummies(X_unl_cat, drop_first=True)\n",
    "        # align columns\n",
    "        X_unl_cat = X_unl_cat.reindex(columns=X_cat.columns, fill_value=0)\n",
    "        X_unl_prepared = pd.concat([X_unl_num, X_unl_cat], axis=1)\n",
    "    else:\n",
    "        X_unl_prepared = X_unl_num\n",
    "    preds = multi_clf.predict(X_unl_prepared)\n",
    "    preds_df = pd.DataFrame(preds, columns=target_cols, index=df_unlabeled.index)\n",
    "    df_unlabeled[target_cols] = preds_df\n",
    "    df_unlabeled[['client_id'] + target_cols].head()\n",
    "    df_unlabeled.to_csv('/mnt/data/unlabeled_with_preds.csv', index=False)\n",
    "    print('Predictions saved to /mnt/data/unlabeled_with_preds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ea1f8",
   "metadata": {},
   "source": [
    "## Notes and next steps\n",
    "- We trained a simple **multi-output RandomForest** with `class_weight='balanced'` to prioritize detection of the **1** class (the 'bad' event).\n",
    "- **Evaluation:** we masked rows where the true label was missing when computing per-target metrics. Use precision/recall/F1 on the 1-class as primary metrics (precision to avoid false positives, recall to catch bad customers).\n",
    "- **Combining models:** a single multi-output model is acceptable when features are shared; alternative is one model per target if per-target hyperparameter tuning is needed.\n",
    "- **Applying to unlabeled:** Save predictions and monitor downstream business signals (e.g., fraction flagged; manual review of a sample; future label arrival) to validate model calibration.\n",
    "- **Improvements:** cross-validated threshold tuning, calibration (Platt/Isotonic), and using probability thresholds different per-target to balance false positives vs false negatives.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
